{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import struct\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "def print_message(s):\n",
    "    print(\"[{}] {}\".format(datetime.datetime.utcnow().strftime(\"%b %d, %H:%M:%S\"), s), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 terms loaded.\n",
      "200 terms loaded.\n",
      "300 terms loaded.\n",
      "400 terms loaded.\n",
      "500 terms loaded.\n",
      "600 terms loaded.\n",
      "700 terms loaded.\n",
      "800 terms loaded.\n",
      "900 terms loaded.\n",
      "1000 terms loaded.\n",
      "1100 terms loaded.\n",
      "1200 terms loaded.\n",
      "1300 terms loaded.\n",
      "1400 terms loaded.\n",
      "1500 terms loaded.\n",
      "1600 terms loaded.\n",
      "1700 terms loaded.\n",
      "1800 terms loaded.\n",
      "1900 terms loaded.\n",
      "2000 terms loaded.\n",
      "2100 terms loaded.\n",
      "2200 terms loaded.\n",
      "2300 terms loaded.\n",
      "2400 terms loaded.\n",
      "2500 terms loaded.\n",
      "2600 terms loaded.\n",
      "2700 terms loaded.\n",
      "2800 terms loaded.\n",
      "2900 terms loaded.\n",
      "3000 terms loaded.\n",
      "3100 terms loaded.\n",
      "3200 terms loaded.\n",
      "3300 terms loaded.\n",
      "3400 terms loaded.\n",
      "3500 terms loaded.\n"
     ]
    }
   ],
   "source": [
    "impacts = {}\n",
    "idfs = {}\n",
    "term_id = 0\n",
    "with open('F:\\\\bmitra\\\\data\\\\quant\\\\bhaskar_data_m0708_filtered\\\\bhd_impacts', mode='rb') as reader:\n",
    "#with open('F:\\\\bmitra\\\\data\\\\quant\\\\bhaskar_data_m0708_filtered\\\\bhd_impacts.v2', mode='rb') as reader:\n",
    "    while reader:\n",
    "        impacts[term_id] = {}\n",
    "        size_packed = reader.read(4)\n",
    "        if len(size_packed) == 4:\n",
    "            size = struct.unpack('i', size_packed)\n",
    "            idfs[term_id] = 1 #struct.unpack('f', reader.read(4))[0]\n",
    "            for i in range(size[0]):\n",
    "                did_packed =  reader.read(4)\n",
    "                did = struct.unpack('i', did_packed)[0]\n",
    "                impacts[term_id][did] = struct.unpack('f', reader.read(4))[0]\n",
    "            term_id = term_id + 1\n",
    "            if term_id % 100 == 0:\n",
    "                print('{} terms loaded.'.format(term_id))\n",
    "        else:\n",
    "            break\n",
    "IMPACTS_MEAN = 0\n",
    "IMPACTS_COUNT = 0\n",
    "IMPACTS_MIN = float(\"inf\")\n",
    "IMPACTS_MAX = 0\n",
    "for k, v in impacts.items():\n",
    "    for k2, v2 in v.items():\n",
    "        IMPACTS_MIN = min(IMPACTS_MIN, v2)\n",
    "        IMPACTS_MAX = max(IMPACTS_MAX, v2)\n",
    "        IMPACTS_MEAN += v2\n",
    "        IMPACTS_COUNT += 1\n",
    "IMPACTS_MEAN /= IMPACTS_COUNT\n",
    "IMPACTS_STD = 0\n",
    "for k, v in impacts.items():\n",
    "    for k2, v2 in v.items():\n",
    "        IMPACTS_STD += (v2 - IMPACTS_MEAN)**2\n",
    "IMPACTS_STD /= IMPACTS_COUNT\n",
    "IMPACTS_STD = IMPACTS_STD**0.5\n",
    "\n",
    "doc_map = {}\n",
    "with open('F:\\\\bmitra\\\\data\\\\quant\\\\bhaskar_data_m0708_filtered\\\\bhd_doc_map.txt', mode='r') as reader:\n",
    "    for line in reader:\n",
    "        cols = line.split(' ')\n",
    "        doc_map[cols[1]] = int(cols[0])\n",
    "        \n",
    "qd_pos = {}\n",
    "qd_neg = {}\n",
    "with open('F:\\\\bmitra\\\\data\\\\quant\\\\bhaskar_data_m0708_filtered\\\\07-08.results.filtered.cust', mode='r') as reader:\n",
    "    for line in reader:\n",
    "        cols = line.split(' ')\n",
    "        qid = int(cols[1])\n",
    "        did = doc_map[cols[4]]\n",
    "        if qid not in qd_pos:\n",
    "            qd_pos[qid] = []\n",
    "            qd_neg[qid] = []\n",
    "        if int(cols[5]) <= 1000:\n",
    "            qd_pos[qid].append(did)\n",
    "        else:\n",
    "            qd_neg[qid].append(did)\n",
    "\n",
    "terms = {}\n",
    "term_id = 0\n",
    "with open('F:\\\\bmitra\\\\data\\\\quant\\\\bhaskar_data_m0708_filtered\\\\bhd_term_stem.txt', mode='r') as reader:\n",
    "    for line in reader:\n",
    "        cols = line.split(' ')\n",
    "        term = cols[1]\n",
    "        terms[term] = term_id\n",
    "        term_id = term_id + 1\n",
    "        \n",
    "q_terms = {}\n",
    "with open('F:\\\\bmitra\\\\data\\\\quant\\\\bhaskar_data_m0708_filtered\\\\07-08.queries.filtered', mode='r') as reader:\n",
    "    for line in reader:\n",
    "        cols = line.split('\\t')\n",
    "        q_terms[int(cols[0])] = [term for term in [terms.get(term) for term in cols[1].strip().split(' ')[:10]]if term is not None]\n",
    "        \n",
    "qrels = {}\n",
    "for qrels_file in ['F:\\\\bmitra\\\\data\\\\quant\\\\bhaskar_data_m0708_filtered\\\\07.prels.txt', 'F:\\\\bmitra\\\\data\\\\quant\\\\bhaskar_data_m0708_filtered\\\\prels']:\n",
    "    with open(qrels_file, mode='r') as reader:\n",
    "        for line in reader:\n",
    "            cols = line.split(' ')\n",
    "            qid = int(cols[0])\n",
    "            if qid not in qrels:\n",
    "                qrels[qid] = set()\n",
    "            if int(cols[2]) > 0:\n",
    "                qrels[qid].add(doc_map[cols[1]])\n",
    "\n",
    "qids = list(qid for (qid, docs) in qd_neg.items() if len(docs) > 0)\n",
    "random.shuffle(qids)\n",
    "split_cnt = int(0.8*len(qids))\n",
    "qids_train = qids[:split_cnt]\n",
    "qids_test = qids[split_cnt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 02, 15:37:07] Starting...\n",
      "[Sep 02, 15:37:48] model: random scores, overlap: 0.10117751479289927, recall: 0.10300096876951861\n",
      "[Sep 02, 15:38:29] model: exact scores, overlap: 0.9886844181459575, recall: 0.8655453971210136\n",
      "[Sep 02, 15:42:50] model: uniformly quantized scores, bins: 2, overlap: 0.10024654832347137, recall: 0.1128778861112227\n",
      "[Sep 02, 15:46:30] model: learned quantized scores, bins: 2, alpha: 8, epochs: 0, loss: NA, overlap: 0.3010946745562133, recall: 0.5400326884197078\n",
      "[Sep 02, 15:58:23] model: learned quantized scores, bins: 2, alpha: 8, epochs: 1, loss: 0.4626709517069685, overlap: 0.2989447731755424, recall: 0.5349217529020001\n",
      "[Sep 02, 16:10:16] model: learned quantized scores, bins: 2, alpha: 8, epochs: 2, loss: 0.46227058895965456, overlap: 0.29987179487179483, recall: 0.5481251864088187\n",
      "[Sep 02, 16:22:07] model: learned quantized scores, bins: 2, alpha: 8, epochs: 3, loss: 0.4626789004141756, overlap: 0.29883037475345187, recall: 0.5330855893536621\n",
      "[Sep 02, 16:34:02] model: learned quantized scores, bins: 2, alpha: 8, epochs: 4, loss: 0.4626108668417146, overlap: 0.30084615384615376, recall: 0.5425296461635982\n",
      "[Sep 02, 16:37:41] model: learned quantized scores, bins: 2, alpha: 16, epochs: 0, loss: NA, overlap: 0.3009230769230768, recall: 0.5427572873904403\n",
      "[Sep 02, 16:49:34] model: learned quantized scores, bins: 2, alpha: 16, epochs: 1, loss: 0.4794279292655119, overlap: 0.29585404339250465, recall: 0.5284756769982583\n",
      "[Sep 02, 17:01:26] model: learned quantized scores, bins: 2, alpha: 16, epochs: 2, loss: 0.47913696901741787, overlap: 0.30068836291913226, recall: 0.5350804140457741\n",
      "[Sep 02, 17:13:19] model: learned quantized scores, bins: 2, alpha: 16, epochs: 3, loss: 0.47941337100201054, overlap: 0.2890591715976331, recall: 0.5132461112559307\n",
      "[Sep 02, 17:25:12] model: learned quantized scores, bins: 2, alpha: 16, epochs: 4, loss: 0.47924562745538424, overlap: 0.2960335305719921, recall: 0.5236069508752522\n",
      "[Sep 02, 17:28:50] model: learned quantized scores, bins: 2, alpha: 32, epochs: 0, loss: NA, overlap: 0.30039447731755436, recall: 0.5492308201522552\n",
      "[Sep 02, 17:40:42] model: learned quantized scores, bins: 2, alpha: 32, epochs: 1, loss: 0.48791559559322195, overlap: 0.2986173570019724, recall: 0.5254132989173468\n",
      "[Sep 02, 17:52:34] model: learned quantized scores, bins: 2, alpha: 32, epochs: 2, loss: 0.487839709930995, overlap: 0.2986686390532546, recall: 0.5234002452532703\n",
      "[Sep 02, 18:04:26] model: learned quantized scores, bins: 2, alpha: 32, epochs: 3, loss: 0.4880127684591571, overlap: 0.30034516765285985, recall: 0.5368569117443572\n",
      "[Sep 02, 18:16:18] model: learned quantized scores, bins: 2, alpha: 32, epochs: 4, loss: 0.48776264496700605, overlap: 0.2906331360946747, recall: 0.5204668366683182\n",
      "[Sep 02, 18:19:57] model: learned quantized scores, bins: 2, alpha: 64, epochs: 0, loss: NA, overlap: 0.30047928994082806, recall: 0.536117005407736\n",
      "[Sep 02, 18:31:53] model: learned quantized scores, bins: 2, alpha: 64, epochs: 1, loss: 0.49267211370170116, overlap: 0.2914575936883628, recall: 0.5250962574097052\n",
      "[Sep 02, 18:43:44] model: learned quantized scores, bins: 2, alpha: 64, epochs: 2, loss: 0.4922967215788958, overlap: 0.28923274161735657, recall: 0.5204112090303851\n",
      "[Sep 02, 18:55:37] model: learned quantized scores, bins: 2, alpha: 64, epochs: 3, loss: 0.4920640047894267, overlap: 0.3000966469428009, recall: 0.5484898228167814\n",
      "[Sep 02, 19:07:28] model: learned quantized scores, bins: 2, alpha: 64, epochs: 4, loss: 0.49240647018814343, overlap: 0.29694082840236713, recall: 0.5404606995231876\n",
      "[Sep 02, 19:11:53] model: uniformly quantized scores, bins: 4, overlap: 0.29268441814595647, recall: 0.5174193852867149\n",
      "[Sep 02, 19:15:38] model: learned quantized scores, bins: 4, alpha: 8, epochs: 0, loss: NA, overlap: 0.35146942800788933, recall: 0.6015950727965695\n",
      "[Sep 02, 19:27:44] model: learned quantized scores, bins: 4, alpha: 8, epochs: 1, loss: 0.1859497158911836, overlap: 0.5196824457593688, recall: 0.7258585130578312\n",
      "[Sep 02, 19:39:48] model: learned quantized scores, bins: 4, alpha: 8, epochs: 2, loss: 0.1850166561507649, overlap: 0.5203944773175545, recall: 0.7400919827016591\n",
      "[Sep 02, 19:51:52] model: learned quantized scores, bins: 4, alpha: 8, epochs: 3, loss: 0.18499970235825458, overlap: 0.5195621301775147, recall: 0.7520893751599153\n",
      "[Sep 02, 20:03:56] model: learned quantized scores, bins: 4, alpha: 8, epochs: 4, loss: 0.18528781739951228, overlap: 0.5147593688362915, recall: 0.7392658218884179\n",
      "[Sep 02, 20:07:42] model: learned quantized scores, bins: 4, alpha: 16, epochs: 0, loss: NA, overlap: 0.35215976331360926, recall: 0.5987693178997647\n",
      "[Sep 02, 20:19:45] model: learned quantized scores, bins: 4, alpha: 16, epochs: 1, loss: 0.21907449204445584, overlap: 0.5224358974358977, recall: 0.7480823476815228\n",
      "[Sep 02, 20:31:50] model: learned quantized scores, bins: 4, alpha: 16, epochs: 2, loss: 0.21871849490526074, overlap: 0.5169644970414203, recall: 0.7271928257053536\n",
      "[Sep 02, 20:43:55] model: learned quantized scores, bins: 4, alpha: 16, epochs: 3, loss: 0.21833149595477153, overlap: 0.5197337278106511, recall: 0.7288574449021349\n",
      "[Sep 02, 20:56:00] model: learned quantized scores, bins: 4, alpha: 16, epochs: 4, loss: 0.21842146426388354, overlap: 0.5198639053254441, recall: 0.7407084244641152\n",
      "[Sep 02, 20:59:46] model: learned quantized scores, bins: 4, alpha: 32, epochs: 0, loss: NA, overlap: 0.35228994082840265, recall: 0.6101562702303975\n",
      "[Sep 02, 21:11:51] model: learned quantized scores, bins: 4, alpha: 32, epochs: 1, loss: 0.23711670091688575, overlap: 0.5219842209072978, recall: 0.7445650731570259\n",
      "[Sep 02, 21:23:55] model: learned quantized scores, bins: 4, alpha: 32, epochs: 2, loss: 0.2362720234086737, overlap: 0.5204536489151874, recall: 0.7195113142362259\n",
      "[Sep 02, 21:35:59] model: learned quantized scores, bins: 4, alpha: 32, epochs: 3, loss: 0.2363828522611584, overlap: 0.5139585798816562, recall: 0.7319020159266458\n",
      "[Sep 02, 21:48:03] model: learned quantized scores, bins: 4, alpha: 32, epochs: 4, loss: 0.2362835192179773, overlap: 0.5203155818540435, recall: 0.7307998658915291\n",
      "[Sep 02, 21:51:48] model: learned quantized scores, bins: 4, alpha: 64, epochs: 0, loss: NA, overlap: 0.35181656804733746, recall: 0.5996945907566475\n",
      "[Sep 02, 22:03:53] model: learned quantized scores, bins: 4, alpha: 64, epochs: 1, loss: 0.24694100513625017, overlap: 0.5209171597633142, recall: 0.7405973964985602\n",
      "[Sep 02, 22:15:58] model: learned quantized scores, bins: 4, alpha: 64, epochs: 2, loss: 0.24556760077575746, overlap: 0.5099999999999999, recall: 0.729281536675526\n",
      "[Sep 02, 22:28:04] model: learned quantized scores, bins: 4, alpha: 64, epochs: 3, loss: 0.24624181491344643, overlap: 0.5044615384615387, recall: 0.7246135149830464\n",
      "[Sep 02, 22:40:07] model: learned quantized scores, bins: 4, alpha: 64, epochs: 4, loss: 0.24702418209744792, overlap: 0.5135581854043391, recall: 0.7216999026363292\n",
      "[Sep 02, 22:44:32] model: uniformly quantized scores, bins: 8, overlap: 0.4018895463510853, recall: 0.6344237127255701\n",
      "[Sep 02, 22:48:26] model: learned quantized scores, bins: 8, alpha: 8, epochs: 0, loss: NA, overlap: 0.3934536489151875, recall: 0.6454392385911604\n",
      "[Sep 02, 23:00:42] model: learned quantized scores, bins: 8, alpha: 8, epochs: 1, loss: 0.050418185607895794, overlap: 0.7046134122287964, recall: 0.8174746534419388\n",
      "[Sep 02, 23:12:58] model: learned quantized scores, bins: 8, alpha: 8, epochs: 2, loss: 0.04780404370239921, overlap: 0.703161735700197, recall: 0.8118748249178812\n",
      "[Sep 02, 23:25:15] model: learned quantized scores, bins: 8, alpha: 8, epochs: 3, loss: 0.04782348018761695, overlap: 0.6989506903353048, recall: 0.8126845663846096\n",
      "[Sep 02, 23:37:30] model: learned quantized scores, bins: 8, alpha: 8, epochs: 4, loss: 0.04796746398392315, overlap: 0.6941913214990139, recall: 0.8240316825911836\n",
      "[Sep 02, 23:41:25] model: learned quantized scores, bins: 8, alpha: 16, epochs: 0, loss: NA, overlap: 0.3924930966469429, recall: 0.639221994096919\n",
      "[Sep 02, 23:53:41] model: learned quantized scores, bins: 8, alpha: 16, epochs: 1, loss: 0.07621154397065766, overlap: 0.7077159763313612, recall: 0.8196294863635829\n",
      "[Sep 03, 00:05:57] model: learned quantized scores, bins: 8, alpha: 16, epochs: 2, loss: 0.07375934358742597, overlap: 0.6972110453648921, recall: 0.8204227570329288\n",
      "[Sep 03, 00:18:12] model: learned quantized scores, bins: 8, alpha: 16, epochs: 3, loss: 0.07377682317837753, overlap: 0.6989842209072978, recall: 0.8210709780475379\n",
      "[Sep 03, 00:30:29] model: learned quantized scores, bins: 8, alpha: 16, epochs: 4, loss: 0.07384386428611833, overlap: 0.703337278106509, recall: 0.8203023559324356\n",
      "[Sep 03, 00:34:24] model: learned quantized scores, bins: 8, alpha: 32, epochs: 0, loss: NA, overlap: 0.39208284023668677, recall: 0.6343577586648653\n",
      "[Sep 03, 00:46:38] model: learned quantized scores, bins: 8, alpha: 32, epochs: 1, loss: 0.09141980296408292, overlap: 0.7105877712031554, recall: 0.8131492213983248\n",
      "[Sep 03, 00:58:54] model: learned quantized scores, bins: 8, alpha: 32, epochs: 2, loss: 0.0881368327909513, overlap: 0.700424063116371, recall: 0.8167611495391959\n",
      "[Sep 03, 01:11:08] model: learned quantized scores, bins: 8, alpha: 32, epochs: 3, loss: 0.08788580598775297, overlap: 0.7097001972386588, recall: 0.8086028822920649\n",
      "[Sep 03, 01:23:23] model: learned quantized scores, bins: 8, alpha: 32, epochs: 4, loss: 0.08817101251315762, overlap: 0.7094635108481265, recall: 0.811548415917247\n",
      "[Sep 03, 01:27:18] model: learned quantized scores, bins: 8, alpha: 64, epochs: 0, loss: NA, overlap: 0.39261538461538475, recall: 0.6516750486165516\n",
      "[Sep 03, 01:39:33] model: learned quantized scores, bins: 8, alpha: 64, epochs: 1, loss: 0.0987826753535046, overlap: 0.7114694280078895, recall: 0.8195765462747924\n",
      "[Sep 03, 01:51:51] model: learned quantized scores, bins: 8, alpha: 64, epochs: 2, loss: 0.09621386456183245, overlap: 0.7077554240631168, recall: 0.8150017426805843\n",
      "[Sep 03, 02:04:07] model: learned quantized scores, bins: 8, alpha: 64, epochs: 3, loss: 0.09622585554643592, overlap: 0.710597633136095, recall: 0.8101895284559751\n",
      "[Sep 03, 02:16:23] model: learned quantized scores, bins: 8, alpha: 64, epochs: 4, loss: 0.09629525611671852, overlap: 0.6994635108481263, recall: 0.816884520292728\n",
      "[Sep 03, 02:20:48] model: uniformly quantized scores, bins: 16, overlap: 0.5382307692307687, recall: 0.7488850850667284\n",
      "[Sep 03, 02:24:47] model: learned quantized scores, bins: 16, alpha: 8, epochs: 0, loss: NA, overlap: 0.3919270216962519, recall: 0.6305456310487798\n",
      "[Sep 03, 02:37:16] model: learned quantized scores, bins: 16, alpha: 8, epochs: 1, loss: 0.018854023602102643, overlap: 0.8122426035502964, recall: 0.8453992702283492\n",
      "[Sep 03, 02:49:41] model: learned quantized scores, bins: 16, alpha: 8, epochs: 2, loss: 0.012252591217247755, overlap: 0.8188362919132145, recall: 0.8539018991735207\n",
      "[Sep 03, 03:02:06] model: learned quantized scores, bins: 16, alpha: 8, epochs: 3, loss: 0.011717832951319451, overlap: 0.815364891518738, recall: 0.8574661385204384\n",
      "[Sep 03, 03:14:31] model: learned quantized scores, bins: 16, alpha: 8, epochs: 4, loss: 0.011745439825745052, overlap: 0.8174299802761333, recall: 0.8467043423196939\n",
      "[Sep 03, 03:18:29] model: learned quantized scores, bins: 16, alpha: 16, epochs: 0, loss: NA, overlap: 0.3917199211045367, recall: 0.6361921459799431\n",
      "[Sep 03, 03:30:56] model: learned quantized scores, bins: 16, alpha: 16, epochs: 1, loss: 0.030854493552965323, overlap: 0.8004398422090722, recall: 0.8438173267285278\n",
      "[Sep 03, 03:43:20] model: learned quantized scores, bins: 16, alpha: 16, epochs: 2, loss: 0.023586645568457243, overlap: 0.8044319526627218, recall: 0.8540636784651429\n",
      "[Sep 03, 03:55:46] model: learned quantized scores, bins: 16, alpha: 16, epochs: 3, loss: 0.02340482485863049, overlap: 0.7738441814595661, recall: 0.8543151134285095\n",
      "[Sep 03, 04:08:13] model: learned quantized scores, bins: 16, alpha: 16, epochs: 4, loss: 0.023470772911878157, overlap: 0.7764871794871799, recall: 0.8622666525391552\n",
      "[Sep 03, 04:12:11] model: learned quantized scores, bins: 16, alpha: 32, epochs: 0, loss: NA, overlap: 0.3918461538461536, recall: 0.6420895148629169\n",
      "[Sep 03, 04:24:38] model: learned quantized scores, bins: 16, alpha: 32, epochs: 1, loss: 0.03946685336245537, overlap: 0.8296449704142009, recall: 0.8612464613495945\n",
      "[Sep 03, 04:37:04] model: learned quantized scores, bins: 16, alpha: 32, epochs: 2, loss: 0.0333552768311165, overlap: 0.8250670611439842, recall: 0.8473720629061924\n",
      "[Sep 03, 04:49:30] model: learned quantized scores, bins: 16, alpha: 32, epochs: 3, loss: 0.033442223340216515, overlap: 0.8240236686390529, recall: 0.8482789900539298\n",
      "[Sep 03, 05:01:55] model: learned quantized scores, bins: 16, alpha: 32, epochs: 4, loss: 0.03342301487032273, overlap: 0.8173629191321498, recall: 0.8466213011926441\n",
      "[Sep 03, 05:05:55] model: learned quantized scores, bins: 16, alpha: 64, epochs: 0, loss: NA, overlap: 0.39214398422090735, recall: 0.6475032443115472\n",
      "[Sep 03, 05:18:21] model: learned quantized scores, bins: 16, alpha: 64, epochs: 1, loss: 0.0479877658544865, overlap: 0.8147810650887575, recall: 0.8517418746434585\n",
      "[Sep 03, 05:30:48] model: learned quantized scores, bins: 16, alpha: 64, epochs: 2, loss: 0.041420333907126405, overlap: 0.8200000000000001, recall: 0.8492234180381629\n",
      "[Sep 03, 05:43:16] model: learned quantized scores, bins: 16, alpha: 64, epochs: 3, loss: 0.041419230466772206, overlap: 0.8112149901380673, recall: 0.853491160715593\n",
      "[Sep 03, 05:55:42] model: learned quantized scores, bins: 16, alpha: 64, epochs: 4, loss: 0.0410334044256615, overlap: 0.821000000000001, recall: 0.8589191444673286\n",
      "[Sep 03, 06:00:06] model: uniformly quantized scores, bins: 32, overlap: 0.64120315581854, recall: 0.8098627001965074\n",
      "[Sep 03, 06:04:14] model: learned quantized scores, bins: 32, alpha: 8, epochs: 0, loss: NA, overlap: 0.5356863905325447, recall: 0.7355108810229555\n",
      "[Sep 03, 06:16:48] model: learned quantized scores, bins: 32, alpha: 8, epochs: 1, loss: 0.012933363592708247, overlap: 0.8714654832347144, recall: 0.8613036319726614\n",
      "[Sep 03, 06:29:21] model: learned quantized scores, bins: 32, alpha: 8, epochs: 2, loss: 0.009416162276693285, overlap: 0.8595088757396447, recall: 0.8515752756489161\n",
      "[Sep 03, 06:41:52] model: learned quantized scores, bins: 32, alpha: 8, epochs: 3, loss: 0.009473145438391839, overlap: 0.860828402366864, recall: 0.8577231159637746\n",
      "[Sep 03, 06:54:22] model: learned quantized scores, bins: 32, alpha: 8, epochs: 4, loss: 0.009465752554604023, overlap: 0.8700473372781062, recall: 0.858573866849601\n",
      "[Sep 03, 06:58:31] model: learned quantized scores, bins: 32, alpha: 16, epochs: 0, loss: NA, overlap: 0.535925049309665, recall: 0.7361978032047785\n",
      "[Sep 03, 07:11:04] model: learned quantized scores, bins: 32, alpha: 16, epochs: 1, loss: 0.015684258004398544, overlap: 0.8761893491124259, recall: 0.8561492310840786\n",
      "[Sep 03, 07:23:38] model: learned quantized scores, bins: 32, alpha: 16, epochs: 2, loss: 0.011981098284536529, overlap: 0.8787830374753446, recall: 0.8586263350479426\n",
      "[Sep 03, 07:36:10] model: learned quantized scores, bins: 32, alpha: 16, epochs: 3, loss: 0.011819045093432123, overlap: 0.8775759368836292, recall: 0.866582356747031\n",
      "[Sep 03, 07:48:44] model: learned quantized scores, bins: 32, alpha: 16, epochs: 4, loss: 0.011863696271745994, overlap: 0.8781597633136098, recall: 0.860226749682049\n",
      "[Sep 03, 07:52:53] model: learned quantized scores, bins: 32, alpha: 32, epochs: 0, loss: NA, overlap: 0.53577909270217, recall: 0.7369487894932755\n",
      "[Sep 03, 08:05:27] model: learned quantized scores, bins: 32, alpha: 32, epochs: 1, loss: 0.021898500869497184, overlap: 0.8749980276134117, recall: 0.8619105637528481\n",
      "[Sep 03, 08:17:59] model: learned quantized scores, bins: 32, alpha: 32, epochs: 2, loss: 0.017019365635007944, overlap: 0.8813668639053251, recall: 0.8609683338485987\n",
      "[Sep 03, 08:30:33] model: learned quantized scores, bins: 32, alpha: 32, epochs: 3, loss: 0.017035091001559977, overlap: 0.8851262327416175, recall: 0.8648217306294447\n",
      "[Sep 03, 08:43:04] model: learned quantized scores, bins: 32, alpha: 32, epochs: 4, loss: 0.017331587504600066, overlap: 0.8806942800788953, recall: 0.8610791432389745\n",
      "[Sep 03, 08:47:14] model: learned quantized scores, bins: 32, alpha: 64, epochs: 0, loss: NA, overlap: 0.5358106508875743, recall: 0.729699477886323\n",
      "[Sep 03, 08:59:45] model: learned quantized scores, bins: 32, alpha: 64, epochs: 1, loss: 0.02673207535747224, overlap: 0.8655207100591719, recall: 0.8624491408353274\n",
      "[Sep 03, 09:12:21] model: learned quantized scores, bins: 32, alpha: 64, epochs: 2, loss: 0.024472535670156503, overlap: 0.8734378698224847, recall: 0.8556648492118075\n",
      "[Sep 03, 09:24:57] model: learned quantized scores, bins: 32, alpha: 64, epochs: 3, loss: 0.024642902409823364, overlap: 0.8473274161735701, recall: 0.8581763186840993\n",
      "[Sep 03, 09:37:29] model: learned quantized scores, bins: 32, alpha: 64, epochs: 4, loss: 0.024488040633400487, overlap: 0.8537080867850093, recall: 0.8612611366555549\n",
      "[Sep 03, 09:41:55] model: uniformly quantized scores, bins: 64, overlap: 0.7102800788954629, recall: 0.8245809907187214\n",
      "[Sep 03, 09:46:08] model: learned quantized scores, bins: 64, alpha: 8, epochs: 0, loss: NA, overlap: 0.5252110453648909, recall: 0.7376663047184703\n",
      "[Sep 03, 09:58:44] model: learned quantized scores, bins: 64, alpha: 8, epochs: 1, loss: 0.016019633949468925, overlap: 0.8846489151873769, recall: 0.864375982158218\n",
      "[Sep 03, 10:11:21] model: learned quantized scores, bins: 64, alpha: 8, epochs: 2, loss: 0.009313611591778681, overlap: 0.8826213017751477, recall: 0.8643067306559569\n",
      "[Sep 03, 10:23:57] model: learned quantized scores, bins: 64, alpha: 8, epochs: 3, loss: 0.009261416310664572, overlap: 0.8620374753451677, recall: 0.8621120285389676\n",
      "[Sep 03, 10:36:34] model: learned quantized scores, bins: 64, alpha: 8, epochs: 4, loss: 0.009272497092155163, overlap: 0.879201183431953, recall: 0.8589919241664506\n",
      "[Sep 03, 10:40:48] model: learned quantized scores, bins: 64, alpha: 16, epochs: 0, loss: NA, overlap: 0.5253195266272189, recall: 0.7338326781445471\n",
      "[Sep 03, 10:53:25] model: learned quantized scores, bins: 64, alpha: 16, epochs: 1, loss: 0.017461556605667283, overlap: 0.8925029585798819, recall: 0.85690023151107\n",
      "[Sep 03, 11:06:02] model: learned quantized scores, bins: 64, alpha: 16, epochs: 2, loss: 0.010639294445155656, overlap: 0.9039723865877712, recall: 0.8627620300059609\n",
      "[Sep 03, 11:18:39] model: learned quantized scores, bins: 64, alpha: 16, epochs: 3, loss: 0.010659929143599811, overlap: 0.8853096646942803, recall: 0.8652580367204996\n",
      "[Sep 03, 11:31:16] model: learned quantized scores, bins: 64, alpha: 16, epochs: 4, loss: 0.010903667168662423, overlap: 0.9013826429980281, recall: 0.8609686364469056\n",
      "[Sep 03, 11:35:30] model: learned quantized scores, bins: 64, alpha: 32, epochs: 0, loss: NA, overlap: 0.5248974358974355, recall: 0.7346594768259331\n",
      "[Sep 03, 11:48:06] model: learned quantized scores, bins: 64, alpha: 32, epochs: 1, loss: 0.020919165631823944, overlap: 0.8974043392504933, recall: 0.8611067100933706\n",
      "[Sep 03, 12:00:44] model: learned quantized scores, bins: 64, alpha: 32, epochs: 2, loss: 0.01357625118271244, overlap: 0.9011814595660763, recall: 0.8658175922482052\n",
      "[Sep 03, 12:13:23] model: learned quantized scores, bins: 64, alpha: 32, epochs: 3, loss: 0.013352240931965298, overlap: 0.9087593688362927, recall: 0.8659627117336105\n",
      "[Sep 03, 12:26:02] model: learned quantized scores, bins: 64, alpha: 32, epochs: 4, loss: 0.01367362798242766, overlap: 0.89748717948718, recall: 0.858462272959165\n",
      "[Sep 03, 12:30:15] model: learned quantized scores, bins: 64, alpha: 64, epochs: 0, loss: NA, overlap: 0.5251321499013807, recall: 0.7356331926147305\n",
      "[Sep 03, 12:42:56] model: learned quantized scores, bins: 64, alpha: 64, epochs: 1, loss: 0.02404279289061151, overlap: 0.90981459566075, recall: 0.8648216215653365\n",
      "[Sep 03, 12:55:38] model: learned quantized scores, bins: 64, alpha: 64, epochs: 2, loss: 0.016828975663372603, overlap: 0.9013609467455633, recall: 0.8588600759794188\n",
      "[Sep 03, 13:08:18] model: learned quantized scores, bins: 64, alpha: 64, epochs: 3, loss: 0.016790297018360434, overlap: 0.9099921104536491, recall: 0.8638446864634014\n",
      "[Sep 03, 13:20:56] model: learned quantized scores, bins: 64, alpha: 64, epochs: 4, loss: 0.018178347921889326, overlap: 0.8931282051282053, recall: 0.8590602313892187\n",
      "[Sep 03, 13:25:21] model: uniformly quantized scores, bins: 128, overlap: 0.7444950690335312, recall: 0.8341167434499381\n",
      "[Sep 03, 13:29:39] model: learned quantized scores, bins: 128, alpha: 8, epochs: 0, loss: NA, overlap: 0.5340493096646936, recall: 0.7371514760278983\n",
      "[Sep 03, 13:42:32] model: learned quantized scores, bins: 128, alpha: 8, epochs: 1, loss: 0.019753553425317705, overlap: 0.9086824457593691, recall: 0.8636436551352283\n",
      "[Sep 03, 13:55:19] model: learned quantized scores, bins: 128, alpha: 8, epochs: 2, loss: 0.009372252550122084, overlap: 0.9045384615384613, recall: 0.8593183147348192\n",
      "[Sep 03, 14:08:02] model: learned quantized scores, bins: 128, alpha: 8, epochs: 3, loss: 0.009230136881711815, overlap: 0.8861479289940827, recall: 0.8639569139650906\n",
      "[Sep 03, 14:20:47] model: learned quantized scores, bins: 128, alpha: 8, epochs: 4, loss: 0.009296974533668845, overlap: 0.890244575936884, recall: 0.8561617292493207\n",
      "[Sep 03, 14:25:05] model: learned quantized scores, bins: 128, alpha: 16, epochs: 0, loss: NA, overlap: 0.5340946745562125, recall: 0.7390259041116308\n",
      "[Sep 03, 14:37:49] model: learned quantized scores, bins: 128, alpha: 16, epochs: 1, loss: 0.021084929680057485, overlap: 0.8990552268244577, recall: 0.8639104444696808\n",
      "[Sep 03, 14:50:34] model: learned quantized scores, bins: 128, alpha: 16, epochs: 2, loss: 0.010361507781567525, overlap: 0.9001558185404345, recall: 0.8616659280444133\n",
      "[Sep 03, 15:03:20] model: learned quantized scores, bins: 128, alpha: 16, epochs: 3, loss: 0.01058429658797877, overlap: 0.9033175542406316, recall: 0.8651751429121991\n",
      "[Sep 03, 15:16:11] model: learned quantized scores, bins: 128, alpha: 16, epochs: 4, loss: 0.010435919829717477, overlap: 0.9159289940828398, recall: 0.8634758383945853\n",
      "[Sep 03, 15:20:28] model: learned quantized scores, bins: 128, alpha: 32, epochs: 0, loss: NA, overlap: 0.5339467455621296, recall: 0.7401437860002078\n",
      "[Sep 03, 15:33:16] model: learned quantized scores, bins: 128, alpha: 32, epochs: 1, loss: 0.02226133175346945, overlap: 0.9167909270216968, recall: 0.8633934802626907\n",
      "[Sep 03, 15:46:00] model: learned quantized scores, bins: 128, alpha: 32, epochs: 2, loss: 0.012240741764856011, overlap: 0.9105424063116373, recall: 0.8663647060082366\n",
      "[Sep 03, 15:58:44] model: learned quantized scores, bins: 128, alpha: 32, epochs: 3, loss: 0.012880207939417687, overlap: 0.9008757396449715, recall: 0.8588033765588535\n",
      "[Sep 03, 16:11:26] model: learned quantized scores, bins: 128, alpha: 32, epochs: 4, loss: 0.013449893916913425, overlap: 0.8946568047337281, recall: 0.865040739240105\n",
      "[Sep 03, 16:15:45] model: learned quantized scores, bins: 128, alpha: 64, epochs: 0, loss: NA, overlap: 0.5338500986193289, recall: 0.7411547905836928\n",
      "[Sep 03, 16:28:31] model: learned quantized scores, bins: 128, alpha: 64, epochs: 1, loss: 0.025644185209785064, overlap: 0.9042544378698228, recall: 0.8702386120096238\n",
      "[Sep 03, 16:41:19] model: learned quantized scores, bins: 128, alpha: 64, epochs: 2, loss: 0.01575740893127886, overlap: 0.8975917159763319, recall: 0.8596634553974707\n",
      "[Sep 03, 16:54:06] model: learned quantized scores, bins: 128, alpha: 64, epochs: 3, loss: 0.016442095867091666, overlap: 0.9001577909270215, recall: 0.8634272945875539\n",
      "[Sep 03, 17:06:49] model: learned quantized scores, bins: 128, alpha: 64, epochs: 4, loss: 0.018036356687105126, overlap: 0.8994773175542398, recall: 0.8643467196105079\n",
      "[Sep 03, 17:11:14] model: uniformly quantized scores, bins: 256, overlap: 0.7667278106508875, recall: 0.8400969319535446\n",
      "[Sep 03, 17:15:37] model: learned quantized scores, bins: 256, alpha: 8, epochs: 0, loss: NA, overlap: 0.5725700197238662, recall: 0.7617103750721235\n",
      "[Sep 03, 17:28:49] model: learned quantized scores, bins: 256, alpha: 8, epochs: 1, loss: 0.023961742322910595, overlap: 0.9203786982248527, recall: 0.8652735284923483\n",
      "[Sep 03, 17:41:58] model: learned quantized scores, bins: 256, alpha: 8, epochs: 2, loss: 0.009421388382946816, overlap: 0.9070059171597631, recall: 0.8627840851696429\n",
      "[Sep 03, 17:55:06] model: learned quantized scores, bins: 256, alpha: 8, epochs: 3, loss: 0.009371946657637409, overlap: 0.9036982248520713, recall: 0.8668528786857812\n",
      "[Sep 03, 18:08:15] model: learned quantized scores, bins: 256, alpha: 8, epochs: 4, loss: 0.009317329205629221, overlap: 0.9010138067061149, recall: 0.8633946122320962\n",
      "[Sep 03, 18:12:37] model: learned quantized scores, bins: 256, alpha: 16, epochs: 0, loss: NA, overlap: 0.5725305719921109, recall: 0.766332485669462\n",
      "[Sep 03, 18:25:50] model: learned quantized scores, bins: 256, alpha: 16, epochs: 1, loss: 0.024452871942656884, overlap: 0.9274970414201187, recall: 0.8626078919114463\n",
      "[Sep 03, 18:39:00] model: learned quantized scores, bins: 256, alpha: 16, epochs: 2, loss: 0.010355115475277898, overlap: 0.9134753451676532, recall: 0.8654005562644769\n",
      "[Sep 03, 18:52:07] model: learned quantized scores, bins: 256, alpha: 16, epochs: 3, loss: 0.010318974914838464, overlap: 0.9147613412228797, recall: 0.863383342774725\n",
      "[Sep 03, 19:05:16] model: learned quantized scores, bins: 256, alpha: 16, epochs: 4, loss: 0.010396543165654748, overlap: 0.9064950690335309, recall: 0.8592642438189634\n",
      "[Sep 03, 19:09:39] model: learned quantized scores, bins: 256, alpha: 32, epochs: 0, loss: NA, overlap: 0.5725088757396448, recall: 0.7578601650149321\n",
      "[Sep 03, 19:22:50] model: learned quantized scores, bins: 256, alpha: 32, epochs: 1, loss: 0.02689406753049184, overlap: 0.9219329388560169, recall: 0.8637110570754299\n",
      "[Sep 03, 19:35:58] model: learned quantized scores, bins: 256, alpha: 32, epochs: 2, loss: 0.011651458464427833, overlap: 0.9144990138067063, recall: 0.8582496000630323\n",
      "[Sep 03, 19:49:07] model: learned quantized scores, bins: 256, alpha: 32, epochs: 3, loss: 0.012150777262917245, overlap: 0.9139980276134125, recall: 0.8613550108442943\n",
      "[Sep 03, 20:02:14] model: learned quantized scores, bins: 256, alpha: 32, epochs: 4, loss: 0.01281080638500498, overlap: 0.9043609467455631, recall: 0.8604114165770432\n",
      "[Sep 03, 20:06:35] model: learned quantized scores, bins: 256, alpha: 64, epochs: 0, loss: NA, overlap: 0.572666666666667, recall: 0.7608122359008552\n",
      "[Sep 03, 20:19:45] model: learned quantized scores, bins: 256, alpha: 64, epochs: 1, loss: 0.02940556712641751, overlap: 0.9216883629191321, recall: 0.8639143278978392\n",
      "[Sep 03, 20:32:53] model: learned quantized scores, bins: 256, alpha: 64, epochs: 2, loss: 0.014401126292568733, overlap: 0.9070591715976328, recall: 0.860206141771324\n",
      "[Sep 03, 20:46:00] model: learned quantized scores, bins: 256, alpha: 64, epochs: 3, loss: 0.015626237099240825, overlap: 0.9045936883629184, recall: 0.8605749760083806\n",
      "[Sep 03, 20:59:07] model: learned quantized scores, bins: 256, alpha: 64, epochs: 4, loss: 0.01592131749816872, overlap: 0.907443786982249, recall: 0.8610926576308524\n",
      "[Sep 03, 21:03:32] model: uniformly quantized scores, bins: 512, overlap: 0.7810749506903354, recall: 0.8385788537242789\n",
      "[Sep 03, 21:07:59] model: learned quantized scores, bins: 512, alpha: 8, epochs: 0, loss: NA, overlap: 0.5640453648915194, recall: 0.751454435671721\n",
      "[Sep 03, 21:22:02] model: learned quantized scores, bins: 512, alpha: 8, epochs: 1, loss: 0.040253961430892105, overlap: 0.9180295857988173, recall: 0.8647614418742152\n",
      "[Sep 03, 21:36:03] model: learned quantized scores, bins: 512, alpha: 8, epochs: 2, loss: 0.009338880648357417, overlap: 0.894641025641026, recall: 0.8608027108713214\n",
      "[Sep 03, 21:50:01] model: learned quantized scores, bins: 512, alpha: 8, epochs: 3, loss: 0.009438229397090936, overlap: 0.9082465483234717, recall: 0.8607684910460218\n",
      "[Sep 03, 22:03:59] model: learned quantized scores, bins: 512, alpha: 8, epochs: 4, loss: 0.009260651088197847, overlap: 0.898625246548324, recall: 0.862205826374512\n",
      "[Sep 03, 22:08:25] model: learned quantized scores, bins: 512, alpha: 16, epochs: 0, loss: NA, overlap: 0.5639723865877716, recall: 0.7517866823158345\n",
      "[Sep 03, 22:22:30] model: learned quantized scores, bins: 512, alpha: 16, epochs: 1, loss: 0.0439634018881776, overlap: 0.9357850098619327, recall: 0.8662241558804047\n",
      "[Sep 03, 22:36:32] model: learned quantized scores, bins: 512, alpha: 16, epochs: 2, loss: 0.010224212093987717, overlap: 0.924116370808679, recall: 0.8675592350584633\n",
      "[Sep 03, 22:50:33] model: learned quantized scores, bins: 512, alpha: 16, epochs: 3, loss: 0.01030363760114028, overlap: 0.9254437869822482, recall: 0.866464336876641\n",
      "[Sep 03, 23:04:36] model: learned quantized scores, bins: 512, alpha: 16, epochs: 4, loss: 0.01031036441494848, overlap: 0.9203175542406321, recall: 0.8699305658317178\n",
      "[Sep 03, 23:09:03] model: learned quantized scores, bins: 512, alpha: 32, epochs: 0, loss: NA, overlap: 0.5642189349112426, recall: 0.752273261695018\n",
      "[Sep 03, 23:23:06] model: learned quantized scores, bins: 512, alpha: 32, epochs: 1, loss: 0.04732552354226982, overlap: 0.92952268244576, recall: 0.8636817579837921\n",
      "[Sep 03, 23:37:07] model: learned quantized scores, bins: 512, alpha: 32, epochs: 2, loss: 0.011386747139397357, overlap: 0.9293629191321497, recall: 0.8679535989984586\n",
      "[Sep 03, 23:51:05] model: learned quantized scores, bins: 512, alpha: 32, epochs: 3, loss: 0.011668819472447467, overlap: 0.9152998027613416, recall: 0.8614978615663526\n",
      "[Sep 04, 00:05:03] model: learned quantized scores, bins: 512, alpha: 32, epochs: 4, loss: 0.011885483362220839, overlap: 0.9168244575936892, recall: 0.8613977561115685\n",
      "[Sep 04, 00:09:29] model: learned quantized scores, bins: 512, alpha: 64, epochs: 0, loss: NA, overlap: 0.564165680473373, recall: 0.7525258233208384\n",
      "[Sep 04, 00:23:33] model: learned quantized scores, bins: 512, alpha: 64, epochs: 1, loss: 0.047876138330579465, overlap: 0.9334516765286003, recall: 0.8659675617378901\n",
      "[Sep 04, 00:37:34] model: learned quantized scores, bins: 512, alpha: 64, epochs: 2, loss: 0.013037841173854758, overlap: 0.9213254437869833, recall: 0.8677875036667245\n",
      "[Sep 04, 00:51:34] model: learned quantized scores, bins: 512, alpha: 64, epochs: 3, loss: 0.014535085872012132, overlap: 0.9206824457593686, recall: 0.8605840701342584\n",
      "[Sep 04, 01:05:31] model: learned quantized scores, bins: 512, alpha: 64, epochs: 4, loss: 0.015080176311982996, overlap: 0.9090276134122287, recall: 0.8600199307425875\n",
      "[Sep 04, 01:09:56] model: uniformly quantized scores, bins: 1024, overlap: 0.7892583826429987, recall: 0.8379715119338165\n",
      "[Sep 04, 01:14:33] model: learned quantized scores, bins: 1024, alpha: 8, epochs: 0, loss: NA, overlap: 0.5873175542406311, recall: 0.7660806901242245\n",
      "[Sep 04, 01:30:35] model: learned quantized scores, bins: 1024, alpha: 8, epochs: 1, loss: 0.0756015906320826, overlap: 0.9095305719921098, recall: 0.8636687758787057\n",
      "[Sep 04, 01:46:39] model: learned quantized scores, bins: 1024, alpha: 8, epochs: 2, loss: 0.009700957155416745, overlap: 0.9171025641025639, recall: 0.8665183075017292\n",
      "[Sep 04, 02:02:37] model: learned quantized scores, bins: 1024, alpha: 8, epochs: 3, loss: 0.009257272466754785, overlap: 0.8998895463510849, recall: 0.8647060044595641\n",
      "[Sep 04, 02:18:39] model: learned quantized scores, bins: 1024, alpha: 8, epochs: 4, loss: 0.009261077685692953, overlap: 0.90984023668639, recall: 0.8628281726248784\n",
      "[Sep 04, 02:23:15] model: learned quantized scores, bins: 1024, alpha: 16, epochs: 0, loss: NA, overlap: 0.5873905325443788, recall: 0.7637593279750287\n",
      "[Sep 04, 02:39:23] model: learned quantized scores, bins: 1024, alpha: 16, epochs: 1, loss: 0.08001095432246075, overlap: 0.9449289940828406, recall: 0.8648685660497956\n",
      "[Sep 04, 02:55:27] model: learned quantized scores, bins: 1024, alpha: 16, epochs: 2, loss: 0.010268994924700792, overlap: 0.9260019723865879, recall: 0.8613269262299057\n",
      "[Sep 04, 03:11:30] model: learned quantized scores, bins: 1024, alpha: 16, epochs: 3, loss: 0.010179474607383554, overlap: 0.9309566074950695, recall: 0.8684308252759191\n",
      "[Sep 04, 03:27:35] model: learned quantized scores, bins: 1024, alpha: 16, epochs: 4, loss: 0.0104548842377028, overlap: 0.9261755424063122, recall: 0.8623929332579628\n",
      "[Sep 04, 03:32:12] model: learned quantized scores, bins: 1024, alpha: 32, epochs: 0, loss: NA, overlap: 0.5873471400394477, recall: 0.7666905027527116\n",
      "[Sep 04, 03:48:19] model: learned quantized scores, bins: 1024, alpha: 32, epochs: 1, loss: 0.0838376045953595, overlap: 0.9355719921104552, recall: 0.8641597088990632\n",
      "[Sep 04, 04:04:20] model: learned quantized scores, bins: 1024, alpha: 32, epochs: 2, loss: 0.011398937419414779, overlap: 0.9266587771203164, recall: 0.8658475965793143\n",
      "[Sep 04, 04:20:19] model: learned quantized scores, bins: 1024, alpha: 32, epochs: 3, loss: 0.011224208193311824, overlap: 0.9231222879684421, recall: 0.8618674823921999\n",
      "[Sep 04, 04:36:20] model: learned quantized scores, bins: 1024, alpha: 32, epochs: 4, loss: 0.011796116039931803, overlap: 0.9163708086785026, recall: 0.8670254970179565\n",
      "[Sep 04, 04:40:56] model: learned quantized scores, bins: 1024, alpha: 64, epochs: 0, loss: NA, overlap: 0.5873037475345166, recall: 0.7649569828996009\n",
      "[Sep 04, 04:57:02] model: learned quantized scores, bins: 1024, alpha: 64, epochs: 1, loss: 0.0870097664381575, overlap: 0.9503431952662721, recall: 0.8637535874357738\n",
      "[Sep 04, 05:13:03] model: learned quantized scores, bins: 1024, alpha: 64, epochs: 2, loss: 0.012466219719613036, overlap: 0.9243767258382647, recall: 0.8645660698404707\n",
      "[Sep 04, 05:29:02] model: learned quantized scores, bins: 1024, alpha: 64, epochs: 3, loss: 0.014336368365491126, overlap: 0.918631163708086, recall: 0.8622829099995293\n",
      "[Sep 04, 05:44:59] model: learned quantized scores, bins: 1024, alpha: 64, epochs: 4, loss: 0.014720429139515545, overlap: 0.9140907297830381, recall: 0.8647467003852594\n",
      "[Sep 04, 05:44:59] Finished\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\")\n",
    "NUM_BINS_TO_TRY = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "ALPHAS_TO_TRY = [8, 16, 32, 64]\n",
    "MAX_TERMS = 10\n",
    "MAX_DOCS_PER_Q = 10000\n",
    "NUM_POS_DOCS = 1000\n",
    "NUM_EPOCHS = 4\n",
    "EPOCH_SIZE = 8192\n",
    "MB_SIZE = len(qids_train)\n",
    "LEARNING_RATE = 0.1\n",
    "EPSILON = 1e-6\n",
    "\n",
    "class Quant(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        super(Quant, self).__init__()\n",
    "        self.scheme = 1\n",
    "        self.alpha = alpha\n",
    "        if self.scheme == 0:\n",
    "            self.w = nn.Parameter(torch.Tensor(1, NUM_BINS - 1))\n",
    "        else:\n",
    "            self.register_parameter('w', None)\n",
    "        self.b = nn.Parameter(torch.Tensor(NUM_BINS - 1))\n",
    "        self.v = nn.Parameter(torch.Tensor(NUM_BINS - 1, 1))\n",
    "        \n",
    "        if self.scheme == 0:\n",
    "            nn.init.normal_(self.w, mean=0, std=1)\n",
    "        nn.init.normal_(self.b, mean=IMPACTS_MEAN, std=IMPACTS_STD)\n",
    "        nn.init.normal_(self.v, mean=IMPACTS_MEAN, std=IMPACTS_STD)\n",
    "\n",
    "    def forward(self, x, idf):\n",
    "        if self.scheme == 0:\n",
    "            return F.softmax((x.mm(self.w) + self.b) * self.alpha).mm(F.softplus(self.v)) * idf\n",
    "        else:\n",
    "            return F.sigmoid((x - F.softplus(self.b)) * self.alpha).mm(F.softplus(self.v)) * idf\n",
    "        \n",
    "    def forward_eval(self, x, idf):\n",
    "        with torch.no_grad():\n",
    "            if self.scheme == 0:\n",
    "                idx = torch.empty(MAX_DOCS_PER_Q, NUM_BINS - 1)\n",
    "                idx.scatter(1, torch.argmax(F.softmax(x.mm(self.w) + self.b).max(1), dim=1, keepdim=True), 1)\n",
    "                return idx.mm(F.softplus(self.v)) * idf\n",
    "            else:\n",
    "                return torch.round_(F.sigmoid(x - F.softplus(self.b))).mm(F.softplus(self.v)) * idf\n",
    "\n",
    "def get_mb_train():\n",
    "    for i in range(2):\n",
    "        for j in range(MAX_TERMS):\n",
    "            feat_train[i][j].fill(np.float32(0))\n",
    "            idf_train[i][j].fill(np.float32(0))\n",
    "    for i in range(MB_SIZE):\n",
    "        qid = qids_train[i]\n",
    "        for j in range(2):\n",
    "            did = random.sample(qd_pos[qid] if j == 0 else qd_neg[qid], 1)[0]\n",
    "            terms = q_terms[qid]\n",
    "            for k in range(len(terms)):\n",
    "                term = terms[k]\n",
    "                impact = impacts[term].get(did, 0)\n",
    "                idf = idfs.get(term, 0)\n",
    "                feat_train[j][k][i, 0] = np.float32(impact)\n",
    "                idf_train[j][k][i, 0] = np.float32(idf)\n",
    "    return feat_train, idf_train\n",
    "\n",
    "def get_mb_test(qid):\n",
    "    labels_test = []\n",
    "    for i in range(MAX_TERMS):\n",
    "        feat_test[i].fill(np.float32(0))\n",
    "        idf_test[i].fill(np.float32(0))\n",
    "    num_pos = len(qd_pos[qid])\n",
    "    num_neg = len(qd_neg[qid])\n",
    "    for i in range(num_pos + num_neg):\n",
    "        if i < num_pos:\n",
    "            did = qd_pos[qid][i]\n",
    "        else:\n",
    "            did = qd_neg[qid][i - num_pos]\n",
    "        terms = q_terms[qid]\n",
    "        for j in range(len(terms)):\n",
    "            term = terms[j]\n",
    "            impact = impacts[term].get(did, 0)\n",
    "            idf = idfs.get(term, 0)\n",
    "            feat_test[j][i, 0] = np.float32(impact)\n",
    "            idf_test[j][i, 0] = np.float32(idf)\n",
    "        labels_test.append(1 if did in qrels[qid] else 0)\n",
    "    return feat_test, idf_test, num_neg, labels_test, len(qrels[qid])\n",
    "\n",
    "feat_train = []\n",
    "idf_train = []\n",
    "for i in range(2):\n",
    "    feat_train.append([])\n",
    "    idf_train.append([])\n",
    "    for j in range(MAX_TERMS):\n",
    "        feat_train[i].append(np.zeros((MB_SIZE, 1), dtype=np.float32))\n",
    "        idf_train[i].append(np.zeros((MB_SIZE, 1), dtype=np.float32))\n",
    "feat_test = []\n",
    "idf_test = []\n",
    "for i in range(MAX_TERMS):\n",
    "    feat_test.append(np.zeros((MAX_DOCS_PER_Q, 1), dtype=np.float32))\n",
    "    idf_test.append(np.zeros((MAX_DOCS_PER_Q, 1), dtype=np.float32))\n",
    "labels = np.zeros((MB_SIZE), dtype=np.int64)\n",
    "\n",
    "print_message('Starting...')\n",
    "\n",
    "overlap = 0\n",
    "recall = 0\n",
    "denom_recall = 0\n",
    "for qid in qids_test:\n",
    "    features, idf, num_neg, labels_test, num_rel = get_mb_test(qid)\n",
    "    scores = [(random.random(), 1 if i < NUM_POS_DOCS else 0, labels_test[i]) for i in range(NUM_POS_DOCS + num_neg)]\n",
    "    random.shuffle(scores)\n",
    "    scores.sort(key=lambda tup: tup[0], reverse=True)\n",
    "    overlap += (sum([rating for (score, rating, ignore) in scores[:NUM_POS_DOCS]]) / NUM_POS_DOCS)\n",
    "    recall += (sum([rating for (score, ignore, rating) in scores[:NUM_POS_DOCS]]) / num_rel) if num_rel > 0 else 0\n",
    "    if num_rel > 0:\n",
    "        denom_recall += 1\n",
    "overlap /= len(qids_test)\n",
    "recall /= denom_recall\n",
    "print_message('model: random scores, overlap: {}, recall: {}'.format(overlap, recall))\n",
    "\n",
    "overlap = 0\n",
    "recall = 0\n",
    "denom_recall = 0\n",
    "for qid in qids_test:\n",
    "    features, idf, num_neg, labels_test, num_rel = get_mb_test(qid)\n",
    "    out = sum([idf[i] * features[i] for i in range(MAX_TERMS)])\n",
    "    scores = [(out[i][0], 1 if i < NUM_POS_DOCS else 0, labels_test[i]) for i in range(NUM_POS_DOCS + num_neg)]\n",
    "    random.shuffle(scores)\n",
    "    scores.sort(key=lambda tup: tup[0], reverse=True)\n",
    "    overlap += (sum([rating for (score, rating, ignore) in scores[:NUM_POS_DOCS]]) / NUM_POS_DOCS)\n",
    "    recall += (sum([rating for (score, ignore, rating) in scores[:NUM_POS_DOCS]]) / num_rel) if num_rel > 0 else 0\n",
    "    if num_rel > 0:\n",
    "        denom_recall += 1\n",
    "overlap /= len(qids_test)\n",
    "recall /= denom_recall\n",
    "print_message('model: exact scores, overlap: {}, recall: {}'.format(overlap, recall))\n",
    "\n",
    "for bins in NUM_BINS_TO_TRY:\n",
    "    \n",
    "    overlap = 0\n",
    "    recall = 0\n",
    "    denom_recall = 0\n",
    "    for qid in qids_test:\n",
    "        features, idf, num_neg, labels_test, num_rel = get_mb_test(qid)\n",
    "        out = [sum([idf[j][i, 0] * math.floor(bins*((math.log(features[j][i, 0]) if features[j][i, 0] > 0 else 0) - math.log(IMPACTS_MIN)) / (math.log(IMPACTS_MAX) - math.log(IMPACTS_MIN) + EPSILON)) for j in range(MAX_TERMS)]) for i in range(NUM_POS_DOCS + num_neg)]\n",
    "        scores = [(out[i], 1 if i < NUM_POS_DOCS else 0, labels_test[i]) for i in range(NUM_POS_DOCS + num_neg)]\n",
    "        random.shuffle(scores)\n",
    "        scores.sort(key=lambda tup: tup[0], reverse=True)\n",
    "        overlap += (sum([rating for (score, rating, ignore) in scores[:NUM_POS_DOCS]]) / NUM_POS_DOCS)\n",
    "        recall += (sum([rating for (score, ignore, rating) in scores[:NUM_POS_DOCS]]) / num_rel) if num_rel > 0 else 0\n",
    "        if num_rel > 0:\n",
    "            denom_recall += 1\n",
    "    overlap /= len(qids_test)\n",
    "    recall /= denom_recall\n",
    "    print_message('model: uniformly quantized scores, bins: {}, overlap: {}, recall: {}'.format(bins, overlap, recall))\n",
    "    for alpha in ALPHAS_TO_TRY:\n",
    "        torch.manual_seed(1)\n",
    "        NUM_BINS = bins\n",
    "        net = Quant(alpha)\n",
    "        net = net.to(DEVICE)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "        net.eval()\n",
    "        overlap = 0\n",
    "        recall = 0\n",
    "        denom_recall = 0\n",
    "        for qid in qids_test:\n",
    "            features, idf, num_neg, labels_test, num_rel = get_mb_test(qid)\n",
    "            out = sum([net.forward_eval(torch.from_numpy(features[i]).to(DEVICE), torch.from_numpy(idf[i][j]).to(DEVICE)) for i in range(MAX_TERMS)]).data.cpu()\n",
    "            scores = [(out[i][0], 1 if i < NUM_POS_DOCS else 0, labels_test[i]) for i in range(NUM_POS_DOCS + num_neg)]\n",
    "            random.shuffle(scores)\n",
    "            scores.sort(key=lambda tup: tup[0], reverse=True)\n",
    "            overlap += (sum([rating for (score, rating, ignore) in scores[:NUM_POS_DOCS]]) / NUM_POS_DOCS)\n",
    "            recall += (sum([rating for (score, ignore, rating) in scores[:NUM_POS_DOCS]]) / num_rel) if num_rel > 0 else 0\n",
    "            if num_rel > 0:\n",
    "                denom_recall += 1\n",
    "        overlap /= len(qids_test)\n",
    "        recall /= denom_recall\n",
    "        print_message('model: learned quantized scores, bins: {}, alpha: {}, epochs: 0, loss: NA, overlap: {}, recall: {}'.format(bins, alpha, overlap, recall))\n",
    "        for ep_idx in range(NUM_EPOCHS):\n",
    "            train_loss = 0.0\n",
    "            net.train()\n",
    "            for mb_idx in range(EPOCH_SIZE):\n",
    "                features, idf = get_mb_train()\n",
    "                out = torch.cat(tuple([sum([net(torch.from_numpy(features[i][j]).to(DEVICE), torch.from_numpy(idf[i][j]).to(DEVICE)) for j in range(MAX_TERMS)]) for i in range(2)]), 1)\n",
    "                loss = criterion(out, torch.from_numpy(labels).to(DEVICE))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            net.eval()\n",
    "            overlap = 0\n",
    "            recall = 0\n",
    "            denom_recall = 0\n",
    "            for qid in qids_test:\n",
    "                features, idf, num_neg, labels_test, num_rel = get_mb_test(qid)\n",
    "                out = sum([net.forward_eval(torch.from_numpy(features[i]).to(DEVICE), torch.from_numpy(idf[i][j]).to(DEVICE)) for i in range(MAX_TERMS)]).data.cpu()\n",
    "                scores = [(out[i][0], 1 if i < NUM_POS_DOCS else 0, labels_test[i]) for i in range(NUM_POS_DOCS + num_neg)]\n",
    "                random.shuffle(scores)\n",
    "                scores.sort(key=lambda tup: tup[0], reverse=True)\n",
    "                overlap += (sum([rating for (score, rating, ignore) in scores[:NUM_POS_DOCS]]) / NUM_POS_DOCS)\n",
    "                recall += (sum([rating for (score, ignore, rating) in scores[:NUM_POS_DOCS]]) / num_rel) if num_rel > 0 else 0\n",
    "                if num_rel > 0:\n",
    "                    denom_recall += 1\n",
    "            overlap /= len(qids_test)\n",
    "            recall /= denom_recall\n",
    "            print_message('model: learned quantized scores, bins: {}, alpha: {}, epochs: {}, loss: {}, overlap: {}, recall: {}'.format(bins, alpha, ep_idx + 1, train_loss / EPOCH_SIZE, overlap, recall))\n",
    "print_message('Finished')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
